{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "openai_api_key= os.environ[\"OPENAI_API_KEY\"]\n",
    "huggingfacehub_api_token= os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\llms\\openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\llms\\openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm= OpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.6)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Australia is Canberra.\n"
     ]
    }
   ],
   "source": [
    "text = \"what is the capital of Australia?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\LangChain\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_hugingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0.5,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 'm a liar , i 'm a liar , i 'm a liar , i 'm a liar , i 'm a liar\n"
     ]
    }
   ],
   "source": [
    "text= \"Can you rite a poem about AI ?\"\n",
    "output = llm_hugingface.predict(text)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=llm.predict(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates And LLM chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell me the capital of this Nepal'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "                                 input_variables=['country'],\n",
    "                                 template = \"tell me the capital of this {country}\"\n",
    "                                )\n",
    "# prompt_template.format(country=\"Nepal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict(prompt_template=prompt_template,text=['India'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Nepal is Kathmandu.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt_template)\n",
    "chain.run('Nepal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Using SImple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"tell me the capital of {country}\"\n",
    "    )\n",
    "capital_chain= LLMChain(llm=llm,prompt=capital_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(\n",
    "                                    input_variables=['capital'],\n",
    "                                    template=\"tell me a famous place from {capital}\"\n",
    ")\n",
    "\n",
    "famous_chain= LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One famous place in New Delhi, the capital of India, is the Red Fort. The Red Fort, also known as Lal Qila, is a historic fort complex that was built in the 17th century by the Mughal emperor Shah Jahan. It served as the main residence for the Mughal emperors until 1857 and is now a UNESCO World Heritage Site. The Red Fort is known for its impressive red sandstone architecture and houses various museums, gardens, and important structures like the Diwan-i-Aam (Hall of Public Audience) and Diwan-i-Khas (Hall of Private Audience). It is also the site where the Prime Minister of India hoists the national flag and delivers a speech on Independence Day, making it a significant symbol of Indian independence.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"tell me the capital of {country}\"\n",
    "    )\n",
    "capital_chain= LLMChain(llm=llm,prompt=capital_prompt,output_key=\"capital\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': 'The capital of India is New Delhi.',\n",
       " 'places': 'One famous place in New Delhi, the capital of India, is the iconic Red Fort (Lal Qila). It is a historic fort complex that was built in the 17th century and served as the main residence of the Mughal emperors. The Red Fort is now a UNESCO World Heritage site and a popular tourist attraction known for its stunning architecture and historical significance.'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chain],\n",
    "input_variables = ['country'],\n",
    "output_variables = ['capital','places'])\n",
    "chain({\"country\":\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm= ChatOpenAI(openai_api_key=openai_api_key,temperature=0.6,model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.6, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Great! I can assist you with that. To make a payment for your car insurance, please provide me with the following information:\\n\\n1. Your policy number\\n2. Your full name\\n3. The amount you wish to pay\\n\\nOnce you provide me with this information, I will guide you through the payment process.')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are an intelligent AI assistant, you are working as a Insurance agent chatbot which helps user in insurance services\"),\n",
    "    HumanMessage(content=\"I want to make a payment for my car Insurance\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(Self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are helpful assistant.when the user given any input, you should answer it in according to the user's question \"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([(\"system\",template),(\"human\",human_template)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt| chatllm | CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The highest scorer in Test cricket is Brian Lara from the West Indies',\n",
       " ' who scored 400 not out against England in 2004.']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"Who is Highest scorer in Test Cricket?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
